{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Scraper    \n",
    "    \n",
    "    Anish Work:\n",
    "- Made a google scraper from scrath after amazon scraper\n",
    "\n",
    "\n",
    "    google_url  = (https://www.google.com/shopping/product/7008326304182003253/reviews?q=google%20home&biw=1280&bih=639&prds=paur:ClkAsKraX5bIBh9mxyx3eoP5_ThWVQXaMDpCgoQ5o1a11DDxlM5RPgqnmQsmVBdPiKv-HORNf_a7b54ZmKDJa3j5-DfFORlGw1qvqVbWEhyV5ApvXZQpQ6CxzRIZAFPVH706XZwfVPbDmxlbW4Tngxvbu1o2NA,rstart:10&sa=X&ved=0ahUKEwj0v9jPtvXfAhUR2FQKHcD7AAMQqSQI_wE)\n",
    "    \n",
    "   product/........../ is the gsin code & putting the gsin code of the product you want will scrape that product\n",
    "   \n",
    "   change rstart:{_pgnumber_}0 for whatever page you want\n",
    "   \n",
    "   \n",
    "## Need to do:\n",
    "\n",
    "\n",
    "   \n",
    "## How to use:\n",
    "\n",
    "- Go to the function ReadGsin and add your gsin code to the list.\n",
    "\n",
    "    (In the url example above it is the ...7008326304182003253...)\n",
    "\n",
    "- Change pg_amounts to how many pages you want to iterate over\n",
    "\n",
    "- After running the kernel the scraped data will be sent to google.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from json import dump,loads\n",
    "from requests import get\n",
    "import json\n",
    "from re import sub\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page 7008326304182003253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "def ParseReviews(gsin,pgnumber):\n",
    "    # This script has only been tested with Amazon.com\n",
    "    \n",
    "    google_url  = ('https://www.google.com/shopping/product/{0}/reviews?q=google%20home&biw=1280&bih=639&prds=paur:ClkAsKraX8Po_BNHjxH-Yuazffm_I6ZTl-XFq7J9Cju-IhsWprvvBNQVbAtjPnj9S-0c283EL4MEVkciNKzFUhQXZKcjVzNzGHrLZrnO3-VSZ8ZUtWFeHIPJ5RIZAFPVH70GN1g15WffBXvfhjuFbXBgEL2GyQ,rstart:{1}0&sa=X&ved=0ahUKEwiz2_iUuPXfAhWHhlQKHTSKCMUQqSQI-gE'\n",
    "    .format(gsin,pgnumber)) #gsin is unique google id\n",
    "    \n",
    "    # Add some recent user agent to prevent amazon from blocking the request \n",
    "    # Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'}\n",
    "    for i in range(5):\n",
    "        response = get(google_url, headers = headers, verify=False, timeout=30)\n",
    "        if response.status_code == 404:\n",
    "            return {\"url\": amazon_url, \"error\": \"page not found\"}\n",
    "        if response.status_code != 200:\n",
    "            continue\n",
    "        \n",
    "        # Removing the null bytes from the response.\n",
    "        cleaned_response = response.text.replace('\\x00', '')\n",
    "        \n",
    "        parser = html.fromstring(cleaned_response)\n",
    "        XPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "        XPATH_REVIEW_SECTION_1 = './/div[@class=\"ESCbSb\"]'\n",
    "        XPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review\"]'\n",
    "        XPATH_AGGREGATE_RATING = '//div[@class=\"A85tye tIrLid\"]/@aria-label'\n",
    "        XPATH_PRODUCT_NAME = '//h1[@id=\"product-name\"]//text()'\n",
    "        XPATH_PRICE = './/span[@class=\"price\"]'\n",
    "\n",
    "        raw_product_price = parser.xpath(XPATH_PRICE)[0].text_content()\n",
    "        raw_product_name = parser.xpath(XPATH_PRODUCT_NAME)[0]\n",
    "        raw_agg_rating = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "        \n",
    "        agg_rating = []\n",
    "        \n",
    "        for i in raw_agg_rating:\n",
    "            agg_rating.append(i.split(' '))\n",
    "            \n",
    "        ratings_dict = {}\n",
    "        for j in agg_rating:\n",
    "            rating_key = j[1]\n",
    "            rating_value = j[0]\n",
    "            ratings_dict.update({rating_key: rating_value})\n",
    "        reviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n",
    "\n",
    "        product_price = ''.join(raw_product_price).replace(',', '')\n",
    "        product_name = ''.join(raw_product_name).strip()\n",
    "\n",
    "        if not reviews:\n",
    "            reviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "        reviews_list = []\n",
    "        \n",
    "        # Parsing individual reviews\n",
    "        for review in reviews:\n",
    "            XPATH_RATING  = './/div[@class=\"vq3ore\"]/@aria-label'\n",
    "            XPATH_REVIEW_HEADER = './/span[@class=\"tukK6e\"]//text()'\n",
    "            XPATH_REVIEW_POSTED_DATE = './/div[@class=\"shop__secondary\"]//text()'\n",
    "            XPATH_REVIEW_TEXT_2 = './/div[@class=\"Ge5tnd pd-reviews__user-review-full\"]//text()'\n",
    "            #Comments DNE\n",
    "            #XPATH_REVIEW_COMMENTS = './/span[@class=\"a-size-base\"]//text()'\n",
    "            XPATH_AUTHOR = './/span[contains(@class,\"shop__secondary\")]//text()'\n",
    "            XPATH_REVIEW_TEXT_3 = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "            #HELPFUL DNE\n",
    "            #XPATH_HELPFUL_VOTE_DIV = './/div[@class=\"a-row a-spacing-small\"]'\n",
    "            XPATH_FROM = './/span[contains(@class,\"e2q0ib\")]//text()'\n",
    "            \n",
    "            raw_review_author = review.xpath(XPATH_AUTHOR)[1].split(' ')[0]\n",
    "            raw_review_rating = review.xpath(XPATH_RATING)[0][0]\n",
    "            raw_review_header = review.xpath(XPATH_REVIEW_HEADER)[0]\n",
    "            raw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)[0]\n",
    "            raw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "            raw_review_from = review.xpath(XPATH_FROM)\n",
    "            \n",
    "\n",
    "            try:\n",
    "                review_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "            except:\n",
    "                review_posted_date = None\n",
    "            review_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "            review_dict = {\n",
    "\n",
    "                                'review_text': review_text,\n",
    "                                'review_posted_date': review_posted_date,\n",
    "                                'review_header': raw_review_header,\n",
    "                                'review_rating': raw_review_rating,\n",
    "                                'review_author': raw_review_author,\n",
    "                                'review_from': raw_review_from\n",
    "\n",
    "                            }\n",
    "            reviews_list.append(review_dict)\n",
    "\n",
    "        data = {\n",
    "                    'ratings': ratings_dict,\n",
    "                    'reviews': reviews_list,\n",
    "                    'url': google_url,\n",
    "                    'name': product_name,\n",
    "                    'price': product_price\n",
    "                \n",
    "                }\n",
    "        return data\n",
    "\n",
    "    return {\"error\": \"failed to process the page\", \"url\": google_url}\n",
    "            \n",
    "\n",
    "def ReadGsin():\n",
    "    # Add your own GSINs here\n",
    "    gsinList = [7008326304182003253]\n",
    "    pg_amounts = 5\n",
    "    extracted_data = []\n",
    "    \n",
    "    for gsin in gsinList:\n",
    "        print(\"Downloading and processing page {0}\".format(gsin))\n",
    "        for i in range(1,pg_amounts+1):   \n",
    "            extracted_data.append(ParseReviews(gsin,i))\n",
    "            sleep(5)\n",
    "    f = open('google.json', 'w')\n",
    "    dump(extracted_data, f, indent=4)\n",
    "    f.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ReadGsin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
